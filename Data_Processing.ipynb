{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a34654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pylogit import choice_tools\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pylogit import choice_tools\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5a3096",
   "metadata": {},
   "source": [
    "**Step 1: Covert the Files into a database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfb21509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Assortment</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>[0.5796182233807586, 0.42038177661924164]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 7, 14]</td>\n",
       "      <td>[0.1391774481903281, 0.40211566218661293, 0.45...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 3, 30, 23]</td>\n",
       "      <td>[0.3584641056553135, 0.1281686726296265, 0.251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 5, 21, 20, 7]</td>\n",
       "      <td>[0.10945075272944618, 0.06742039394070407, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 23, 2, 19, 11, 28]</td>\n",
       "      <td>[0.20553684973140704, 0.0846429998294485, 0.05...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Assortment                                        Probability\n",
       "0                  [0, 2]          [0.5796182233807586, 0.42038177661924164]\n",
       "1              [0, 7, 14]  [0.1391774481903281, 0.40211566218661293, 0.45...\n",
       "2          [0, 3, 30, 23]  [0.3584641056553135, 0.1281686726296265, 0.251...\n",
       "3       [0, 5, 21, 20, 7]  [0.10945075272944618, 0.06742039394070407, 0.0...\n",
       "4  [0, 23, 2, 19, 11, 28]  [0.20553684973140704, 0.0846429998294485, 0.05..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Function to read a file where each line is a Python list literal\n",
    "def read_list_literal_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        \n",
    "        data = [ast.literal_eval(line.strip()) for line in file]\n",
    "    return data\n",
    "\n",
    "# Function to read a file where each line is a float number\n",
    "def read_float_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = [(line.strip()) for line in file]\n",
    "    return data\n",
    "\n",
    "# Read the data from the files\n",
    "assortment_data = read_list_literal_file('assortment.txt')\n",
    "probability_data = read_float_file('probability.txt')\n",
    "\n",
    "# Convert the data into pandas DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Assortment': assortment_data,\n",
    "    'Probability': probability_data\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('clean_train.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95742b1c",
   "metadata": {},
   "source": [
    "**Step 2 : Simulate the choice data: assume the product with the highest probability in each assortment was chosen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8add06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Chosen</th>\n",
       "      <th>Assortment_ID</th>\n",
       "      <th>Cores</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>TDP</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.579618</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.420382</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.139177</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.402116</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>0.458707</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Product  Probability  Chosen  Assortment_ID  Cores  Frequency  TDP  Price\n",
       "0        0     0.579618       1              0      0          0    0      0\n",
       "1        2     0.420382       0              0      0          0    0      0\n",
       "2        0     0.139177       0              1      0          0    0      0\n",
       "3        7     0.402116       0              1      0          0    0      0\n",
       "4       14     0.458707       1              1      0          0    0      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "df_clean_train = pd.read_csv('clean_train.csv')\n",
    "# Convert the string representations of lists into actual lists\n",
    "df_clean_train['Assortment'] = df_clean_train['Assortment'].apply(ast.literal_eval)\n",
    "df_clean_train['Probability'] = df_clean_train['Probability'].apply(ast.literal_eval)\n",
    "\n",
    "# Expand the DataFrame to a long format\n",
    "rows = []\n",
    "for _, row in df_clean_train.iterrows():\n",
    "    for product, probability in zip(row['Assortment'], row['Probability']):\n",
    "        rows.append({'Product': product, 'Probability': probability})\n",
    "\n",
    "# Create a new DataFrame\n",
    "df_long_format = pd.DataFrame(rows)\n",
    "\n",
    "# Simulate the choice data: assume the product with the highest probability in each assortment was chosen\n",
    "# For simplicity, we'll assume the product index corresponds to the SKU ID in the assortments\n",
    "df_long_format['Chosen'] = 0  # Initialize all as not chosen\n",
    "# Get the index of the max probability in each assortment and set as chosen\n",
    "for idx, group in df_clean_train.iterrows():\n",
    "    chosen_idx = group['Probability'].index(max(group['Probability']))\n",
    "    chosen_product = group['Assortment'][chosen_idx]\n",
    "    # Set the chosen product in the long format dataframe\n",
    "    df_long_format.loc[(df_long_format['Product'] == chosen_product) & (df_long_format.index == idx), 'Chosen'] = 1\n",
    "#1 and 0 got dog problem\n",
    "# Correcting the logic to mark 'Chosen' products based on the highest probability within each assortment group\n",
    "\n",
    "# First, we need to identify each assortment group. We'll add an 'Assortment_ID' to df_long_format to do this.\n",
    "df_long_format['Assortment_ID'] = df_clean_train.index.repeat(df_clean_train['Assortment'].str.len()).values\n",
    "\n",
    "# Now, we can group by 'Assortment_ID' and mark the product with the highest probability as chosen\n",
    "df_long_format['Chosen'] = 0  # Reset all to not chosen\n",
    "\n",
    "for assortment_id, group in df_long_format.groupby('Assortment_ID'):\n",
    "    # Find the index of the row with the max probability in the group\n",
    "    idx_max_prob = group['Probability'].idxmax()\n",
    "    # Set 'Chosen' to 1 for this product\n",
    "    df_long_format.at[idx_max_prob, 'Chosen'] = 1\n",
    "\n",
    "df_long_format['Cores'] = 0 \n",
    "df_long_format['Frequency'] = 0 \n",
    "df_long_format['TDP'] = 0 \n",
    "df_long_format['Price'] = 0 \n",
    "# Let's take a look at the resulting long format DataFrame\n",
    "df_long_format.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af8455b",
   "metadata": {},
   "source": [
    "**Step 3 Mapping of data base on the context**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0d6656",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mi\\AppData\\Local\\Temp\\ipykernel_17496\\2404755099.py:17: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '3.2' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_long_format.loc[i,'Frequency'] = 3.2\n"
     ]
    }
   ],
   "source": [
    "# Create price levels for each product\n",
    "prices_all_products = [1800, 3000, 2700, 2400, 2100]\n",
    "cores = [4, 8, 8, 4, 4, 4]\n",
    "freq = [3.2, 2.9, 2.9, 2.9, 3.2, 3.2]\n",
    "TDP = [95, 60, 95, 60, 60, 135]\n",
    "\n",
    "# Reshape data for MNLogit\n",
    "for i, rows in df_long_format.iterrows():\n",
    "    x = df_long_format['Product'][i]\n",
    "    if x == 0:\n",
    "        df_long_format.loc[i,'Cores'] = 0\n",
    "        df_long_format.loc[i,'Frequency'] = 0\n",
    "        df_long_format.loc[i,'TDP'] = 0\n",
    "        df_long_format.loc[i,'Price'] = 0\n",
    "    elif x <6:\n",
    "        df_long_format.loc[i,'Cores'] = 4\n",
    "        df_long_format.loc[i,'Frequency'] = 3.2\n",
    "        df_long_format.loc[i,'TDP'] = 95\n",
    "        df_long_format.loc[i,'Price'] = prices_all_products[x%5]\n",
    "    elif x < 11:\n",
    "        df_long_format.loc[i,'Cores'] = 8\n",
    "        df_long_format.loc[i,'Frequency'] = 2.9\n",
    "        df_long_format.loc[i,'TDP'] = 60\n",
    "        df_long_format.loc[i,'Price'] = prices_all_products[x%5]\n",
    "    elif x < 16:\n",
    "        df_long_format.loc[i,'Cores'] = 8\n",
    "        df_long_format.loc[i,'Frequency'] = 2.9\n",
    "        df_long_format.loc[i,'TDP'] = 95\n",
    "        df_long_format.loc[i,'Price'] = prices_all_products[x%5]\n",
    "    elif x < 21:\n",
    "        df_long_format.loc[i,'Cores'] = 4\n",
    "        df_long_format.loc[i,'Frequency'] = 2.9\n",
    "        df_long_format.loc[i,'TDP'] = 60\n",
    "        df_long_format.loc[i,'Price'] = prices_all_products[x%5]\n",
    "    elif x < 26:\n",
    "        df_long_format.loc[i,'Cores'] = 4\n",
    "        df_long_format.loc[i,'Frequency'] = 3.2\n",
    "        df_long_format.loc[i,'TDP'] = 60\n",
    "        df_long_format.loc[i,'Price'] = prices_all_products[x%5]\n",
    "    else:\n",
    "        df_long_format.loc[i,'Cores'] = 4\n",
    "        df_long_format.loc[i,'Frequency'] = 2.2\n",
    "        df_long_format.loc[i,'TDP'] = 135\n",
    "        df_long_format.loc[i,'Price'] = prices_all_products[x%5]\n",
    "\n",
    "mnl_data2 = pd.DataFrame(df_long_format)\n",
    "\n",
    "mnl_data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2e0972",
   "metadata": {},
   "source": [
    "**Step 4: Split the original training data to clean_train and clean_test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa8bfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "train_df.to_csv('clean_train.csv', index=False)\n",
    "\n",
    "test_df.to_csv('clean_test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5692bca",
   "metadata": {},
   "source": [
    "**Step 5: Convert clean_train to clean_train_long**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e2d2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "df_clean_train = pd.read_csv('clean_train.csv')\n",
    "# Convert the string representations of lists into actual lists\n",
    "df_clean_train['Assortment'] = df_clean_train['Assortment'].apply(ast.literal_eval)\n",
    "df_clean_train['Probability'] = df_clean_train['Probability'].apply(ast.literal_eval)\n",
    "\n",
    "# Expand the DataFrame to a long format\n",
    "rows = []\n",
    "for _, row in df_clean_train.iterrows():\n",
    "    for product, probability in zip(row['Assortment'], row['Probability']):\n",
    "        rows.append({'Product': product, 'Probability': probability})\n",
    "\n",
    "# Create a new DataFrame\n",
    "df_long_format = pd.DataFrame(rows)\n",
    "\n",
    "# Simulate the choice data: assume the product with the highest probability in each assortment was chosen\n",
    "# For simplicity, we'll assume the product index corresponds to the SKU ID in the assortments\n",
    "df_long_format['Chosen'] = 0  # Initialize all as not chosen\n",
    "# Get the index of the max probability in each assortment and set as chosen\n",
    "for idx, group in df_clean_train.iterrows():\n",
    "    chosen_idx = group['Probability'].index(max(group['Probability']))\n",
    "    chosen_product = group['Assortment'][chosen_idx]\n",
    "    # Set the chosen product in the long format dataframe\n",
    "    df_long_format.loc[(df_long_format['Product'] == chosen_product) & (df_long_format.index == idx), 'Chosen'] = 1\n",
    "#1 and 0 got dog problem\n",
    "# Correcting the logic to mark 'Chosen' products based on the highest probability within each assortment group\n",
    "\n",
    "# First, we need to identify each assortment group. We'll add an 'Assortment_ID' to df_long_format to do this.\n",
    "df_long_format['Assortment_ID'] = df_clean_train.index.repeat(df_clean_train['Assortment'].str.len()).values\n",
    "\n",
    "# Now, we can group by 'Assortment_ID' and mark the product with the highest probability as chosen\n",
    "df_long_format['Chosen'] = 0  # Reset all to not chosen\n",
    "\n",
    "for assortment_id, group in df_long_format.groupby('Assortment_ID'):\n",
    "    # Find the index of the row with the max probability in the group\n",
    "    idx_max_prob = group['Probability'].idxmax()\n",
    "    # Set 'Chosen' to 1 for this product\n",
    "    df_long_format.at[idx_max_prob, 'Chosen'] = 1\n",
    "\n",
    "df_long_format['Cores'] = 0 \n",
    "df_long_format['Frequency'] = 0 \n",
    "df_long_format['TDP'] = 0 \n",
    "df_long_format['Price'] = 0 \n",
    "# Let's take a look at the resulting long format DataFrame\n",
    "df_long_format.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf218621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create price levels for each product\n",
    "prices_all_products = [1800, 3000, 2700, 2400, 2100]\n",
    "cores = [4, 8, 8, 4, 4, 4]\n",
    "freq = [3.2, 2.9, 2.9, 2.9, 3.2, 3.2]\n",
    "TDP = [95, 60, 95, 60, 60, 135]\n",
    "\n",
    "# Reshape data for MNLogit\n",
    "for i, rows in df_long_format.iterrows():\n",
    "    x = df_long_format['Product'][i]\n",
    "    if x == 0:\n",
    "        df_long_format.loc[i,'Cores'] = 0\n",
    "        df_long_format.loc[i,'Frequency'] = 0\n",
    "        df_long_format.loc[i,'TDP'] = 0\n",
    "        df_long_format.loc[i,'Price'] = 0\n",
    "    elif x <6:\n",
    "        df_long_format.loc[i,'Cores'] = 4\n",
    "        df_long_format.loc[i,'Frequency'] = 3.2\n",
    "        df_long_format.loc[i,'TDP'] = 95\n",
    "        df_long_format.loc[i,'Price'] = prices_all_products[x%5]\n",
    "    elif x < 11:\n",
    "        df_long_format.loc[i,'Cores'] = 8\n",
    "        df_long_format.loc[i,'Frequency'] = 2.9\n",
    "        df_long_format.loc[i,'TDP'] = 60\n",
    "        df_long_format.loc[i,'Price'] = prices_all_products[x%5]\n",
    "    elif x < 16:\n",
    "        df_long_format.loc[i,'Cores'] = 8\n",
    "        df_long_format.loc[i,'Frequency'] = 2.9\n",
    "        df_long_format.loc[i,'TDP'] = 95\n",
    "        df_long_format.loc[i,'Price'] = prices_all_products[x%5]\n",
    "    elif x < 21:\n",
    "        df_long_format.loc[i,'Cores'] = 4\n",
    "        df_long_format.loc[i,'Frequency'] = 2.9\n",
    "        df_long_format.loc[i,'TDP'] = 60\n",
    "        df_long_format.loc[i,'Price'] = prices_all_products[x%5]\n",
    "    elif x < 26:\n",
    "        df_long_format.loc[i,'Cores'] = 4\n",
    "        df_long_format.loc[i,'Frequency'] = 3.2\n",
    "        df_long_format.loc[i,'TDP'] = 60\n",
    "        df_long_format.loc[i,'Price'] = prices_all_products[x%5]\n",
    "    else:\n",
    "        df_long_format.loc[i,'Cores'] = 4\n",
    "        df_long_format.loc[i,'Frequency'] = 2.2\n",
    "        df_long_format.loc[i,'TDP'] = 135\n",
    "        df_long_format.loc[i,'Price'] = prices_all_products[x%5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8446ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnl_data = pd.DataFrame(df_long_format)\n",
    "\n",
    "mnl_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e461f1",
   "metadata": {},
   "source": [
    "**Step 6: Consolidation of Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd9e995",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "mnl_data2.to_csv('Trainingdata2.csv', index=False) #This is the original data set \n",
    "\n",
    "\n",
    "mnl_data.to_csv('clean_train_long.csv', index=False) # this is 0.8 of the training set. the other 0.2 is for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c704e634",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
